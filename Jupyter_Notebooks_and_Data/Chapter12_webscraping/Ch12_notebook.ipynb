{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: Sample Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all code from Chapter 12: _Collecting Data from the Internet_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 EDGAR Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2.1 EDGAR Index Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "def get_index(start_year:int,end_year:int,down_direct:str):\n",
    "    \"\"\"Downloads SEC  EDGAR Index Files.\n",
    "    start_year - > First Year to download\n",
    "    end_year-> Last Year to download\n",
    "    down_direct->Directory to download files to\n",
    "    \"\"\"\n",
    "    print('Downloading Index Files')\n",
    "    # Check if the download folder exists.\n",
    "    if not os.path.exists(down_direct):\n",
    "        # Create the directory if it does not exist.\n",
    "        os.makedirs(down_direct)\n",
    "    # Loop through each year and quarter\n",
    "    for year in range(start_year, end_year+1):\n",
    "        for qtr in range(1,5):\n",
    "            # Specify the file you want to download.\n",
    "            url='https://www.sec.gov/Archives/edgar/full-index/'+str(year)+'/'+'QTR'+str(qtr)+'/master.idx'\n",
    "            # Specify the file name and location \n",
    "            # to download to.\n",
    "            dl_file=down_direct+'master'+str(year)+str(qtr)+'.idx'\n",
    "            # Download the file.\n",
    "            urllib.request.urlretrieve(url, dl_file)  \n",
    "            # Print the name of the downloaded file\n",
    "            print('Downloaded',dl_file,end='\\n')\n",
    "    print('Downloading of Index Files Complete')\n",
    "    return\n",
    "\n",
    "# Specify the location of the folder where index files \n",
    "# will be downloaded to\n",
    "down_direct = os.path.join(Path.home(), 'edgar', 'indexfiles')\n",
    "# Execute the get_index function and download filings \n",
    "# from 2018, 2019, to the folder /\n",
    "get_index(2018, 2019, down_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2.2 Download SEC Filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def get_files(start_year:int, end_year:int,\n",
    "              reform:str, \n",
    "              inddirect:str, odirect:str):\n",
    "    \"\"\"\n",
    "    Downloads SEC filings for specific companies\n",
    "    start_year -> First Year to download\n",
    "    end_year -> Last Year to download\n",
    "    reform -> Regex to specify forms to be downloaded\n",
    "    inddirect -> Directory containing index files\n",
    "    odirect -> Directory the filings will be downloaded to\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Downloading Filings')\n",
    "    \n",
    "    # Regex to identify the form to download.\n",
    "    re_formtype = re.compile(reform, re.IGNORECASE)\n",
    "    # Regex to extract file name information \n",
    "    # from a line\n",
    "    re_fullfilename = re.compile(r\"\\|(edgar/data.*\\/([\\d-]+\\.txt))\", re.IGNORECASE)\n",
    "    \n",
    "    #loop through the index files based on year\n",
    "    for year in range(start_year, end_year+1):\n",
    "        #check whether the directory exists and create one \n",
    "        # if it does not.\n",
    "        download_path = os.path.join(odirect, str(year))\n",
    "        if not os.path.exists(download_path):\n",
    "            os.makedirs(download_path)\n",
    "                \n",
    "        for qtr in range(1,5):\n",
    "            #name of index file to be read.\n",
    "            dl_file = os.path.join(inddirect, 'master' + str(year) + str(qtr) + '.idx')\n",
    "        \n",
    "            # check to see if the index file exists.\n",
    "            if not os.access(dl_file, os.R_OK):\n",
    "                # Download the index file if it does not \n",
    "                # already exist\n",
    "                url='https://www.sec.gov/Archives/edgar/full-index/' + str(year) + '/' + 'QTR' + str(qtr) + '/master.idx'\n",
    "                # download the file defined as url and \n",
    "                # download to the file defined a dl_fle.\n",
    "                urllib.request.urlretrieve(url, dl_file)\n",
    "            # open the index file\n",
    "            with open(dl_file, 'r') as f:\n",
    "                # set a counter called count to 1. Note \n",
    "                # that the counter will only be incremented \n",
    "                # after it downloads a file.\n",
    "                count=1\n",
    "                \n",
    "                # loop through each line in the index file, \n",
    "                # assigning to a variable called line\n",
    "                for line in f:\n",
    "                    # Only download a file if the counter \n",
    "                    # is less than 5.\n",
    "                    # Remove this if statement if you want\n",
    "                    # to download all the files for the\n",
    "                    # time period\n",
    "                    if count<5:\n",
    "                        # Check to see if the the line  \n",
    "                        # matches the form type \n",
    "                        rematch=re.search(re_formtype,line)\n",
    "                        #If there is a match then download \n",
    "                        # the filing\n",
    "                        if rematch:\n",
    "                            # The following line searches \n",
    "                            # for filename information. \n",
    "                            # The first grouping will \n",
    "                            # contain the location and \n",
    "                            # filename of the file to be \n",
    "                            # downloaded. The second\n",
    "                            # grouping will contain just \n",
    "                            # the filename o\n",
    "                            matches = re.search(re_fullfilename, line)\n",
    "                            if matches:\n",
    "                                # Construct the url to for \n",
    "                                # retrieving the filing \n",
    "                                url = str('https://www.sec.gov/Archives/') + str(matches.group(1))\n",
    "                                # Create the filename to \n",
    "                                # download the file to.\n",
    "                                outfile = os.path.join(download_path, \n",
    "                                                       str(matches.group(2)))\n",
    "                                # Check to make sure the  \n",
    "                                # file hasn't already \n",
    "                                # been downloaded\n",
    "                                                       \n",
    "                                if not (os.path.isfile(outfile) and os.access(outfile, os.R_OK)):\n",
    "                                    # Print the name of the \n",
    "                                    # file to be downloaded.\n",
    "                                    print(\"Downloading:\"+str(outfile),end='\\n')\n",
    "                                    #downlaod the file\n",
    "                                    urllib.request.urlretrieve(url, outfile)    \n",
    "                                    count += 1\n",
    "    print('Downloading of Filings Complete',end='\\n')\n",
    "    return\n",
    "                                                       \n",
    "# Specify, in regular expression format, the filing\n",
    "# you are looking for.  Following is the for 10-k.\n",
    "reform='(\\|10-?k(sb|sb40|405)?\\s*\\|)'\n",
    "\n",
    "# Specify location of the index files.\n",
    "inddirect = os.path.join(Path.home(), 'edgar', 'indexfiles')\n",
    "\n",
    "# Specify where to download filings to\n",
    "odirect = os.path.join(Path.home(), 'edgar', '10K')\n",
    "\n",
    "# Execute the get filings function\n",
    "get_files(2018, 2019, reform, inddirect, odirect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2.3 Read Filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def process_header(start_year:int, end_year:int, \n",
    "                   filings:str, outfile:str):\n",
    "    \"\"\" Extracts header information from 10-K filings.\n",
    "    Parameters:\n",
    "    start_year -> First Year to process\n",
    "    end_year -> Last Year to process\n",
    "    filings -> Directory containing files to process\n",
    "    outfile -> CSV file output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a \"dictionary\" of regular expressions for \n",
    "    # each of the variables we want to get. A \n",
    "    # dictionary contains \"keys\" and \"values.\"  In \n",
    "    # this case, for example, the key \"cik\", refers\n",
    "    # to the regular expression for the cik number.\n",
    "    edgar_vars={\n",
    "        \"file\" : re.compile('<SEC-DOCUMENT>(.*\\.txt)', re.IGNORECASE),\n",
    "        \"cik\" : re.compile('^\\s*CENTRAL\\s*INDEX\\s*KEY:\\s*(\\d{10})', re.IGNORECASE),\n",
    "        \"report_date\" : re.compile('^\\s*CONFORMED\\s*PERIOD\\s*OF\\s*REPORT:\\s*(\\d{8})', re.IGNORECASE),\n",
    "        \"file_date\" : re.compile('^\\s*FILED\\s*AS\\s*OF\\s*DATE:\\s*(\\d{8})', re.IGNORECASE),\n",
    "        \"name\" : re.compile('^\\s*COMPANY\\s*CONFORMED\\s*NAME:\\s*(.+)', re.IGNORECASE),\n",
    "        \"sic\" : re.compile('^\\s*STANDARD\\s*INDUSTRIAL\\s*CLASSIFICATION:.*?(\\d{4})', re.IGNORECASE),\n",
    "        \"hlink\" : re.compile(r'(.*?(([0]*(\\d+))\\-(\\d{2})\\-(\\d{6})))', re.IGNORECASE)\n",
    "    } \n",
    "    # create a regular expression representing the \n",
    "    # last row of the file you want to read. The tag\n",
    "    # '</SEC-HEADER>' represents the end of the \n",
    "    # Header information in the .txt file.  All the \n",
    "    # header information should be found before this\n",
    "    # line\n",
    "    regex_endheader = re.compile(r'</SEC-HEADER>', re.IGNORECASE)\n",
    "\n",
    "    # Create a dataframe that has column names \n",
    "    # identical to those we defined in our \n",
    "    # dictionary. The \"keys()\" method creates \n",
    "    # a list of just the keys in the dictionary\n",
    "    # This means, edgar_vars.keys(), is a list \n",
    "    # that looks like this:\n",
    "    # [\"file\", \"cik\", \"report_date\", \"file_date\", \"name\", \"sic\", \"hlink\"]\n",
    "    eframe = pd.DataFrame(columns = edgar_vars.keys())   \n",
    "    \n",
    "    # loop through each of the year folders in \n",
    "    # filings\n",
    "    for year in range(start_year, end_year+1):\n",
    "        # specify the files to process\n",
    "        path = os.path.join(filings,str(year),'*.txt')\n",
    "        # read in the names of each of the files \n",
    "        # contained in the folder\n",
    "        files=glob.glob(path)\n",
    "        # process one file at a time.\n",
    "        for file in files:\n",
    "            # Create a dictionary to hold the \n",
    "            # information we are obtaining \n",
    "            # (e.g., cik number)\n",
    "            header_vars={}\n",
    "            # For each of the keys contained \n",
    "            # in the dictionary, set the initial \n",
    "            # value to -99. This way we are sure\n",
    "            # that each item is defined in the \n",
    "            # dictionary even if we cannot\n",
    "            # find the value.\n",
    "            for x in edgar_vars.keys():\n",
    "                header_vars[x]=-99\n",
    "            # Open the file we are processing \n",
    "            # and read it in one line at a time.\n",
    "            f=open(file, 'r')\n",
    "            for line in f:\n",
    "                # The \"items\" method converts \n",
    "                # the dictionary into a list \n",
    "                # that is easy to operate on\n",
    "                tems=edgar_vars.items()\n",
    "                # Loop through the dictionary \n",
    "                # and assign the key to \"k\" \n",
    "                # and the value to \"v\"\n",
    "                # For example, the first time \n",
    "                # through, k=\"file\", and \n",
    "                # v=\"re.compile('<SEC-DOCUMENT>(.*\\.txt)', re.IGNORECASE)\"\n",
    "                for k, v in tems:\n",
    "                    match = v.search(line)\n",
    "                    # if a match is found for the first\n",
    "                    # time, add it to the dictionary \n",
    "                    # containing the header values.\n",
    "                    # The purpose of the expression, \n",
    "                    # re_key!=\"hlink\" is to not try and \n",
    "                    # match the hlink expression.\n",
    "                    # The hlink expression is used at \n",
    "                    # the end to create a hyperlink to \n",
    "                    # the file on edgar.\n",
    "                    if match and header_vars[k]==-99 and k!=\"hlink\":\n",
    "                        header_vars[k]=match.group(1)\n",
    "                # Check to see if we are at the end \n",
    "                # of the header part of the filing.\n",
    "                # Exit if we are there\n",
    "                match = regex_endheader.search(line)  \n",
    "                if match:\n",
    "                    break\n",
    "            f.close()\n",
    "            # Create a link to the file on edgar\n",
    "            if header_vars['file'] != -99:\n",
    "                #Construct a link to the actual filing \n",
    "                match = edgar_vars['hlink'].search(header_vars['file']) \n",
    "                if match:\n",
    "                    header_vars['hlink'] = str('http://www.sec.gov/Archives/edgar/data/')+str(header_vars['cik'].lstrip('0'))+str(\"/\")+str(match.group(3))+str(match.group(5))+str(match.group(6))+str(\"/\")+str(match.group(2))+str(\"-index.htm\")\n",
    "                #add the row to our dataframe\n",
    "                eframe.loc[len(eframe)] = header_vars     \n",
    "\n",
    "    # Write to csv file\n",
    "    eframe.to_csv(outfile, sep=\",\", encoding='utf-8')\n",
    "    print(f'Header File: {outfile} created')\n",
    "    return eframe\n",
    "\n",
    "# You can change the name of the output file below.\n",
    "outfile = os.path.join(Path.home(), \n",
    "                       'edgar', \n",
    "                       'filingsoutput.csv')\n",
    " #Location of filings to be processed\n",
    "filings = os.path.join(Path.home(), 'edgar', '10K')\n",
    "\n",
    "edgar_dat = process_header(2018,2019,filings,outfile)\n",
    "edgar_dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3 Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from dateutil import parser as dateparse\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def get_aaers(start_year:int, end_year:int,\n",
    "              down_folder:str, csv_file:str):\n",
    "    # create a dataframe to store the list of AAERS\n",
    "    aaer_table = pd.DataFrame(columns = ['aaer_number', \n",
    "                                         'date',\n",
    "                                         'defendant',\n",
    "                                         'link'])\n",
    "    # loop through each year of AAERS\n",
    "    for year in range(start_year, end_year+1):\n",
    "        print(year)\n",
    "        # Define the URL to get\n",
    "        url = 'https://www.sec.gov/divisions/enforce/friactions/friactions' + str(year) + '.shtml'\n",
    "        # download the file\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        print('here')\n",
    "        \n",
    "        # extract html from response object\n",
    "        data = response.text\n",
    "        # parse the HTML.\n",
    "        soup = BeautifulSoup(data, 'lxml')\n",
    "        # The AAER table is the 5th table in the \n",
    "        # document prior to 2016. It is the first\n",
    "        # table after that. So the table number\n",
    "        # is specified as follows:\n",
    "        if year > 2015:\n",
    "            idx = 0\n",
    "        else:\n",
    "            idx = 4\n",
    "        # Grab the table\n",
    "        table = soup.find_all('table')[idx]\n",
    "        # loop through each row - each AAER\n",
    "        for row in table.find_all('tr'):\n",
    "            # Get the columns contained in the row\n",
    "            columns = row.find_all('td')\n",
    "            # make sure there is at least one column\n",
    "            if columns:\n",
    "                # make sure that the first column contains\n",
    "                # the tag 'a'\n",
    "                if columns[0].find('a'):\n",
    "                    # make sure that the first column \n",
    "                    # contains a hyperlink\n",
    "                    if columns[0].find('a').get('href'):\n",
    "                        # create a variable containing a \n",
    "                        # link to the AAER\n",
    "                        link = 'https://www.sec.gov' + str(columns[0].find('a').get('href'))\n",
    "                        # get the AAER number \n",
    "                        # (e.g., AAER-1209)\n",
    "                        aaer = columns[0].find('a').contents[0]\n",
    "                        # remove the \"AAER-\" from AAER \n",
    "                        # so there is just number\n",
    "                        aaer_num = re.findall(r\"\\d+\",aaer)[0]\n",
    "                        # Use date parsing package to \n",
    "                        # parse the date.\n",
    "                        dt = dateparse.parse(columns[1].contents[0])\n",
    "                        aaerdate = str(dt.year) + str(dt.month).zfill(2) + str(dt.day).zfill(2)\n",
    "                        defendant = columns[2].contents[0]\n",
    "                        # add the row to our dataframe\n",
    "                        aaer_table.loc[len(aaer_table)] = [aaer_num,aaerdate,defendant,link]\n",
    "                        # check to see if the AAER is \n",
    "                        # a pdf or htm file.\n",
    "                        if link.find('pdf')!= -1:\n",
    "                            ftype='.pdf'\n",
    "                        else:\n",
    "                            ftype='.htm'\n",
    "                        # name of file to download to\n",
    "                        dl_file = os.path.join(down_folder, str(aaer_num) + ftype)\n",
    "                        \n",
    "                        print(dl_file)\n",
    "                        \n",
    "                        # download the file if not already \n",
    "                        # been downloaded.\n",
    "                        if not (os.path.isfile(dl_file) and os.access(dl_file, os.R_OK)):\n",
    "                            urllib.request.urlretrieve(link, dl_file)\n",
    "    # output the pandas table to a csv file\n",
    "    aaer_table.to_csv(csv_file,index=False)\n",
    "    return aaer_table\n",
    "\n",
    "# Name of folder to download aaers to\n",
    "down_folder = os.path.join(Path.home(), 'aaers')\n",
    "#Name of file that will include list of aaers\n",
    "csv_file = os.path.join(down_folder, 'aaers.csv')\n",
    "#Download and create a pandas dataframe of AAERs\n",
    "aaers = get_aaers(1999, 2019, down_folder, csv_file)\n",
    "#display pandas table\n",
    "aaers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

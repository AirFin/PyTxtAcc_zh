{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11: Sample Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all code from Chapter 11: _Identifying Specific Information in Text_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Example: Extracting Management Discussion \\& Analysis Section from a plain-text 10-K filing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# a regex to identify the location of Item 7 (MD&A) heading\n",
    "# re.DOTALL flag allows . character to match new line \n",
    "# characters; needed for case when heading titles span \n",
    "# multiple lines\n",
    "item7_regex = re.compile(r\"(item.{1,5})?\\b7\\b.{1,5}management.{1,5}discussion.{1,5}analysis\", \n",
    "                         re.IGNORECASE | re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD&A is typically followed by Item 8, \n",
    "# \"Financial Statements and Supplementary Data\"\n",
    "# However, sometimes it is followed by \"Summary of Selected \n",
    "# Financial Data\" section\n",
    "item8_regex = re.compile(r\"(item.{1,5})?\\b8\\b.{1,5}(financial.{1,5}statements.{1,5}supplement.{1,5}data|summary.{1,5}selected.{1,5}financial.{1,5}data)\", re.IGNORECASE | re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mdna(plain_text:str):\n",
    "    \"\"\"Extracts MD&A section from a plain-text 10-K filing\"\"\"\n",
    "    # tries to find position of Item 7 heading\n",
    "    section_start_match = item7_regex.search(plain_text)\n",
    "    # if the attempt was successful, tries to identify \n",
    "    # location of the subsequent section heading\n",
    "    if section_start_match:\n",
    "        # saves the text position of Item 7 heading to \n",
    "        # a variable. Method start() returns the position\n",
    "        # of the regex match in the text\n",
    "        section_start_pos = section_start_match.start()\n",
    "        # finds position of Item 8 heading; starts search \n",
    "        # after Item 7 heading position.\n",
    "        section_end_match = item8_regex.search(plain_text,section_start_pos)\n",
    "        # if Item 8 heading was identified, saves its \n",
    "        # position to a variable\n",
    "        if section_end_match:\n",
    "            section_end_pos = section_end_match.start()\n",
    "            # finally, extracts all text in-between\n",
    "            # text[a:b] allows to extract text (substring) \n",
    "            # between a and b positions\n",
    "            item7_text = plain_text[section_start_pos:section_end_pos]\n",
    "            # returns the content of the MD&A section\n",
    "            return item7_text\n",
    "    # if neither Item 7 nor Item 8 heading was \n",
    "    # identified, returns None\n",
    "    # note that the function will only reach the following \n",
    "    # line of code if the heading search failed\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " foods have been introduced to international  markets.\n",
      "Principal  international  markets include Brazil,  France,  Mexico,  Poland, the\n",
      "Netherlands, South Africa, Spain and the United Kingdom.\n",
      "\n",
      "COMPETITION\n",
      "\n",
      "      Both of PepsiCo's  businesses are highly competitive.  PepsiCo's beverages\n",
      "and snack fo\n"
     ]
    }
   ],
   "source": [
    "# requests is a built-in Python library for \n",
    "# HTTP (web) requests\n",
    "import requests\n",
    "\n",
    "# PepsiCo's 1997 10-K filings files are accessible \n",
    "# through the URL link below:\n",
    "# https://www.sec.gov/Archives/edgar/data/77476/0000077476-98-000014-index.html\n",
    "# generates an HTTP request to download \n",
    "# PepsiCo's 1997 10-K filing\n",
    "response = requests.get('https://www.sec.gov/Archives/edgar/data/77476/0000077476-98-000014.txt')\n",
    "\n",
    "# saves the response (filing) text to a variable\n",
    "text_complete_10k = response.text\n",
    "\n",
    "# checks if the 10-K file was downloaded correctly\n",
    "# prints 300 characters of the text starting at \n",
    "# 10000 character position\n",
    "print(text_complete_10k[10000:10300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 7. Management's Discussion and Analysis of Results of Operations, Cash\n",
      "Flows and Liquidity and Capital Resources\n",
      "\n",
      "Management's Discussion and Analysis\n",
      "\n",
      "All per share information is computed using\n",
      "\n",
      "[...]\n",
      "\n",
      "pital markets throughout the world.\n",
      "\n",
      "ITEM 7A. QUANTITATIVE AND QUALITATIVE DISCLOSURES ABOUT MARKET RISK.\n",
      "\n",
      "Included in Item 7, Management's Discussion and Analysis - Market Risk beginning\n",
      "on page 9.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extracts the MD&A section from the PepsiCo's 10-K \n",
    "# filing text\n",
    "text_mdna_only = extract_mdna(text_complete_10k)\n",
    "\n",
    "# checks if the MD&A section extraction was successful\n",
    "# prints the first 200 characters of the MD&A section\n",
    "print(text_mdna_only[:200])\n",
    "print('\\n[...]\\n')\n",
    "# prints the last 200 characters of the MD&A section\n",
    "print(text_mdna_only[-200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Example: Extracting Management Discussion \\& Analysis Section From an HTML 10-K filing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.2 Writing Code to Identify Section Titles in HTML Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# list of regex patterns that identify HTML text styles \n",
    "# commonly used to display section headings\n",
    "html_styles = [\n",
    "          # b tag; bold text\n",
    "          r\"<b>(?P<value>.+?)</b>\",\n",
    "          # u tag; underlined text\n",
    "          r\"<u>(?P<value>.+?)</u>\",\n",
    "          # strong tag; important text\n",
    "          r\"<strong[^>]*>(?P<value>.+?)</strong>\",\n",
    "          # center tag; centered text\n",
    "          r\"<center[^>]*>(?P<value>.+?)</center>\",\n",
    "          # any tag that has an attribute (\"style\") with \n",
    "          # 'font-weight: bold' value\n",
    "          r\"<(?P<tag>[\\w-]+)\\b[^>]*font-weight:\\s*bold[^>]*>(?P<value>.+?)</(?P=tag)>\",\n",
    "          # any tag that has an attribute (\"style\") with \n",
    "          # 'text-decoration: underline' value\n",
    "          r\"<(?P<tag>[\\w-]+)\\b[^>]*text-decoration:\\s*underline[^>]*>(?P<value>.+?)</(?P=tag)>\",\n",
    "          # em tag; emphasized text\n",
    "          r\"<em>(?P<value>.+?)</em>\"]\n",
    "\n",
    "# function that for a given regex HTML style pattern and \n",
    "# HTML source (document) returns all the (text) values of\n",
    "# HTML elements that match that HTML style along with their\n",
    "# positions (indexes) in the document's HTML source code\n",
    "def get_html_style_values(html_style:str, html_source:str):\n",
    "    # creates a regular expression from the input \n",
    "    # HTML style pattern\n",
    "    html_style_regex = re.compile(html_style, re.IGNORECASE | re.DOTALL)\n",
    "    # finds all the matches for the above regular \n",
    "    # expression in the HTML document\n",
    "    style_matches = html_style_regex.finditer(html_source)\n",
    "    # creates a dictionary list to store the value (text) \n",
    "    # of all regex matches and their positions\n",
    "    results = [{'text':m['value'],'position':m.start()} for m in style_matches]\n",
    "    # outputs results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dding-bottom:2px;padding-right:2px;\"><div style=\"text-align:center;font-size:7pt;\"><font style=\"font-family:Arial;font-size:7pt;font-weight:bold;\">(Zip Code)</font></div></td></tr></table></div></div><div style=\"line-height:120%;padding-top:2px;text-align:center;font-size:9pt;\"><font style=\"font-fam\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Boeing's 2015 10-K files are accessible through the \n",
    "# URL link below:\n",
    "# https://www.sec.gov/Archives/edgar/data/12927/000001292716000099/0000012927-16-000099-index.htm\n",
    "# generates a HTTP request to download Boeing's \n",
    "# 2015 HTML 10-K filing:\n",
    "response = requests.get('https://www.sec.gov/Archives/edgar/data/12927/000001292716000099/a201512dec3110k.htm')\n",
    "\n",
    "# saves the response (filing) source HTML to a variable\n",
    "html_complete_10k = response.text\n",
    "\n",
    "# checks if the 10-K file was downloaded correctly\n",
    "# prints 300 characters of the HTML source code \n",
    "# starting at 10000 character position\n",
    "# the output should look like HTML source code\n",
    "print(html_complete_10k[10000:10300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'UNITED STATES', 'position': 753}\n",
      "{'text': 'SECURITIES AND EXCHANGE COMMISSION', 'position': 906}\n",
      "{'text': 'Washington, D.C. 20549', 'position': 1080}\n"
     ]
    }
   ],
   "source": [
    "# gets all text from the HTML 10-K filing defined using \n",
    "# <center> element\n",
    "style_values = get_html_style_values(html_styles[4], html_complete_10k)\n",
    "\n",
    "# displays the first three instances of such text\n",
    "for i in range(3):\n",
    "    print(style_values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a regex to identify the location of Item 7 (MD&A) heading\n",
    "item7_regex = re.compile(r\"management.{1,20}discussion.{1,20}analysis\", re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "# MD&A is typically followed by Item 8 heading\n",
    "item8_regex = re.compile(r\"financial.{1,20}statements.{1,20}supplement.{1,20}data|summary.{1,20}selected.{1,20}financial.{1,20}data\", re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "def extract_mdna(html_source:str):\n",
    "    \"\"\"Extracts the MD&A section from an HTML filing\"\"\"\n",
    "    # iterates over all possible HTML styles for headings \n",
    "    # until we can identify MD&A section or until we \n",
    "    # exhaust all the styles and fail to identify the \n",
    "    # MD&A section\n",
    "    for style in html_styles:\n",
    "        # gets all text in the input HTML document that \n",
    "        # matches the current style\n",
    "        style_values = get_html_style_values(style, \n",
    "                                             html_source)\n",
    "        # attempts to identify the heading of Item 7 \n",
    "        # (MD&A) section\n",
    "        section_start = next((v for v in style_values\n",
    "                              if item7_regex.search(v['text'])),None)\n",
    "        # if Item 7 heading position is identified, \n",
    "        # proceeds with identifying Item 8 section\n",
    "        if section_start:\n",
    "            # Item 8 heading location should be after Item 7\n",
    "            section_end = next((v for v in style_values \n",
    "                                if item8_regex.search(v['text']) \n",
    "                                and v['position'] > section_start['position']), None)\n",
    "            # if Item 8 heading position is identified, extracts the \n",
    "            # HTML code of the MD&A section\n",
    "            if section_end:\n",
    "                item7_html = html_source[section_start['position']:section_end['position']]\n",
    "                # outputs the HTML code of the MD&A section\n",
    "                return item7_html\n",
    "    # note that the function will reach the following line \n",
    "    # of code only if the heading search failed\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<font style=\"font-family:Arial;font-size:10pt;font-weight:bold;\">Item&#160;7. Management&#8217;s Discussion and Analysis of Financial Condition and Results of Operations</font></div><a name=\"sAE854BB7\n"
     ]
    }
   ],
   "source": [
    "html_mdna_only = extract_mdna(html_complete_10k)\n",
    "\n",
    "# checks if the MD&A section extraction was successful\n",
    "# prints the first 200 characters of the MD&A section\n",
    "print(html_mdna_only[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lxml is a library that parses XML and HTML source code\n",
    "import lxml.html\n",
    "\n",
    "# converts HTML code to plain text\n",
    "def get_text_from_html(html:str):\n",
    "    # creates an lxml document object\n",
    "    doc = lxml.html.fromstring(html)\n",
    "    # optional: removes tables from the HTML source code\n",
    "    for table in doc.xpath('.//table'):\n",
    "        table.getparent().remove(table)\n",
    "    # preserves line breaks\n",
    "    # HTML tags in the list below should be followed by \n",
    "    # new line character\n",
    "    for tag in [\"a\", \"p\", \"div\", \"br\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\"]:\n",
    "        # finds all elements for a given tag\n",
    "        for element in doc.findall(tag):\n",
    "            # if the text value is non-empty adds a \n",
    "            # new line character (line break)\n",
    "            if element.text:\n",
    "                element.text = element.text + \"\\n\"\n",
    "            # else creates a text value with a \n",
    "            # new line character\n",
    "            else:\n",
    "                element.text = \"\\n\"\n",
    "    # extracts and output text from the HTML source code\n",
    "    return doc.text_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 7. Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
      "\n",
      "Consolidated Results of Operations and Financial Condition\n",
      "Overview\n",
      "We are a global market leader in design, development, manufacture, sale, service and support of commercial jetliners, military aircraft, \n"
     ]
    }
   ],
   "source": [
    "# extracts text from the HTML MD&A\n",
    "mdna_text = get_text_from_html(html_mdna_only)\n",
    "# prints the first 300 characters of the MD&A section\n",
    "print(mdna_text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 Extracting text from XBRL financial reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"US-ASCII\"?>\n",
      "<!--XBRL Document Created with WebFilings-->\n",
      "<!--p:ee88abc9bc7d42cca8267c157db83ce8,x:1ee976a4cce447438165efc656d0aac8-->\n",
      "<xbrli:xbrl xmlns:country=\"http://xbrl.sec.gov/country/2013-01-31\" xmlns:dei=\"http://xbrl.sec.gov/dei/2013-01-31\" xmlns:hd=\"http://www.homedepot.com/20140202\" xmlns:invest=\"http://xbrl.sec.gov/invest/2013-01-31\" xmlns:iso4217=\"http://ww\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Home Depot's 2013 10-K files are accessible through \n",
    "# the URL link below:\n",
    "# https://www.sec.gov/Archives/edgar/data/354950/000035495014000008/0000354950-14-000008-index.htm\n",
    "# generates an HTTP request to download Home Depot's \n",
    "# 2013 XBRL 10-K instance file\n",
    "response = requests.get('https://www.sec.gov/Archives/edgar/data/354950/000035495014000008/hd-20140202.xml')\n",
    "\n",
    "# saves the response (filing content) a variable\n",
    "xbrl_10k = response.text\n",
    "\n",
    "# checks if the 10-K file was downloaded correctly\n",
    "# prints the first 400 characters of the XBRL 10-K \n",
    "# instance document\n",
    "print(xbrl_10k[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INCOME TAXES\n",
      "The components of Earnings before Provision for Income Taxes for fiscal 2013, 2012 and 2011 were as follows (amounts in millions):\n",
      " \n",
      "\n",
      "\n",
      "The Provision for Income Taxes consisted of the following (amounts in millions):\n",
      " \n",
      "\n",
      "The Company’s combined federal, state and foreign effective tax rat\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# html.unescape is a built-in Python function to decode HTML characters\n",
    "from html import unescape\n",
    "\n",
    "# regular expression that captures content of the income tax footnote\n",
    "tax_footnote_regex = re.compile(r\"<us-gaap:IncomeTaxDisclosureTextBlock[^>]*>(?P<value>.+?)</us-gaap:IncomeTaxDisclosureTextBlock>\", re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "# XBRL documents report text values in HTML format. However, the HTML characters have to be decoded first.\n",
    "tax_footnote_html = unescape(tax_footnote_regex.search(xbrl_10k)['value'])\n",
    "\n",
    "# converts HTML income tax footnote to the plain-text format\n",
    "tax_footnote_text = get_text_from_html(tax_footnote_html)\n",
    "\n",
    "# outputs the first 300 characters\n",
    "print(tax_footnote_text[:300])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
